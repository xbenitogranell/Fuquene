---
title: "WORKFLOW for data analyses of Fuquene record"
author: 'Author: Xavier Benito (xavier.benito.granell@gmail.com)'
date: 'Date: 11/05/2022'
output:
  html_notebook: default
  pdf_document: default
---

## Introduction
This workflow is written as a R Markdown document to show initial exploratory analyses of paleoclimatic and paleoenvironmental evolution of Lake Fuquene (Colombia, 2540m elevation, 5°27′N, 73°46′W). This document shows the most relevant code. See R files within the folder "scripts" for a more specific code. 

### Study area and datasets description
+ **Lake Fuquene**: Pleistocene in origin, morrained-dammed tropical lake located in the Eastern Cordiellera of Colombian Andes. Water depth=2-6 m

### Three sediment cores, composite of 250 kyr diatom, geochemical and pollen record
+ **F9**: 60-m long, sampled for diatom, pollen and geochemistry
+ **F7**: sampled for diatoms and pollen
+ **M1**: sampled for diatoms and pollen


## Main numerical steps:
+ Clean data and estimate Principal Curves for each assemblage (pollen and diatoms)
+ Plot stratigraphical floristic changes over time to identify periods of change
+ Interpolate PrC from coarser to lower resolution 
+ GAM covariates model
+ HGAM-derivatives: assemblage-wide rate of change


### Load packages 
```{r packages, echo=TRUE, message=FALSE, warning=FALSE}
library(analogue)
library(tidyverse)
library(vegan)
library(analogue)
library(mgcv)
library(ggplot2)
library(gratia)
```

## Step 1: Clean data and estimate Principal Curves (PrC) of the diatom composite core (M1, F7 and F9)
PrC is a nonlinear ordination technique that extracts a single gradient of variation from multivariate data.

```{r principal curves diatoms, echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
F_diatoms <- read.csv("data/Fuquene_diatoms_counts.csv")
nms_diat <- read.csv("data/nms_changes_diatoms_M1_F7_F9.csv")
#rename(core=ï..core) #rename extraneous column name 

agedepth <- F_diatoms[, names(F_diatoms) %in% c("depth", "upper_age", "lower_age", "core")] 
diat <- F_diatoms[, !names(F_diatoms) %in% c("depth", "upper_age", "lower_age", "core")]
diat[is.na(diat)] <- 0

diatoms_save <- cbind(agedepth, diat)

colnames(diatoms_save[,5:ncol(diatoms_save)]) -> nms_diat[,1]

#this is to transform to tidy format, calculate % and subset more common species
new <- diatoms_save %>% 
  gather(key = taxa, value = count, -depth, -upper_age, -lower_age, -core) %>%
  mutate(taxa = plyr::mapvalues(taxa, from = nms_diat[,1], to = nms_diat[,2])) %>%
  group_by(depth, taxa, upper_age, lower_age) %>%
  summarise(count = sum(count)) %>%
  filter(!count == "0") %>% #this is to remove empty samples (rows)
  filter(!upper_age==0.0) %>% #this is to drop extraneous ages
  filter(!is.na(lower_age)) %>%
  ungroup() %>%
  group_by(depth) %>%
  mutate(relative_abundance_percent = count / sum(count) * 100) %>%
  mutate(elapsedTime = abs(upper_age - lower_age)) %>%
  mutate(negAge=-upper_age) %>%
  ungroup() 


# filter more abundant taxa; format need to be on long-wide format-->no spreaded 
core_common_taxa <- new %>%
  group_by(taxa) %>%
  summarise(max_rel_abund = max(relative_abundance_percent)) %>%
  filter(max_rel_abund >= 5) %>%
  arrange(max_rel_abund) %>%
  pull(taxa)

# select from initial table
core_counts_common <- new %>%
  filter(taxa %in% core_common_taxa) %>%
  mutate(taxa = factor(taxa, levels = core_common_taxa)) %>%
  arrange(taxa)

#make it wide
core_counts_wide_diatoms <- core_counts_common %>%
  select(depth, upper_age, lower_age, taxa, relative_abundance_percent) %>%
  spread(key = taxa, value = relative_abundance_percent) %>%
  arrange(upper_age) #sort by increasing time

levels(core_counts_common$taxa)

```

### Check temporal resolution of diatom record
```{r}
median(diff(core_counts_wide_diatoms$upper_age))
plot.ts(diff(core_counts_wide_diatoms$upper_age))
```

### Estime PrC and plot trends
```{r PrC diatoms, echo=FALSE, error=FALSE, message=FALSE, warning=FALSE}
## extract agedepth variables
agedepth <- core_counts_wide_diatoms[,names(core_counts_wide_diatoms) %in% c("depth", "upper_age", "lower_age")]
diatoms <- core_counts_wide_diatoms[,!(names(core_counts_wide_diatoms) %in% c("upper_age", "lower_age", "depth"))]

# Transform data to Hellinger form
diatoms[is.na(diatoms)] <- 0 #Replace NA (if any) by 0
diat_hell <- decostand(diatoms, method="hellinger")

# Run Principal Curves
diat_prc <- prcurve(diat_hell, method = "ca", trace = TRUE, vary = TRUE, penalty = 1.4)

## Extract position on the curve
scrs_prc <- scores(diat_prc, display = "curve")

# Combine dataframe with ages and depths
diatomsPrC <- cbind(agedepth, scrs_prc)
diatomsPrC$proxy <- "diatoms"

# Plot Pcurves with depth and ages
diat_plt_prc <- ggplot(diatomsPrC, aes(x = upper_age, y = PrC)) +
  geom_line() + geom_point() +
  labs(y = "PrC", x = "Age (cal yr BP)", title = "") +
  ggtitle("Diatoms PrC") +
  theme_bw()
diat_plt_prc

```

## Stratigraphic diatom plot

### First do CONISS classification to see statistically significant stratigraphic zones
```{r CONISS diatom, echo=FALSE, message=FALSE, warning=FALSE}
library(rioja)

#do coniss to add statistically significant stratigraphic zones
core_counts_wide_diatoms[is.na(core_counts_wide_diatoms)] <- 0
      
diatHel <- decostand(core_counts_wide_diatoms[,4:ncol(core_counts_wide_diatoms)], method="hellinger")
diss <- vegdist(diatHel, method="bray")
clust <- chclust(diss, method="coniss")
bstick(clust)

#doesn't work
zones <- cutree(clust, k=8)
locate <- cumsum(rle(zones)$lengths)+1
zones <- core_counts_wide_diatoms[locate, ][,2]
zones <- zones$upper_age

```

```{r stratiplot, results='markup'}
## Using tidypaleo R package (https://fishandwhistle.net/post/2018/stratigraphic-diagrams-with-tidypaleo-ggplot2/)
library(tidypaleo) #remotes::install_github("paleolimbot/tidypaleo")
library(patchwork)

theme_set(theme_bw(9))

core_counts_common <- core_counts_common %>%
  group_by(depth) %>%
  mutate(total_sample = sum(count)) %>% 
  filter(total_sample>100) %>%
  mutate(relative_abundance_percent = count / sum(count) * 100) %>%
  ungroup() %>%
  filter(!is.na(elapsedTime)) %>%
  mutate(spp = factor(taxa)) %>%
  droplevels()

levels(core_counts_common$taxa)

# Plot  
diat_plot <- ggplot(core_counts_common, aes(x = relative_abundance_percent, y = upper_age)) +
  geom_col_segsh() +
  scale_y_reverse() +
  facet_abundanceh(vars(taxa)) +
  labs(x = "Relative abundance (%)", y = "Cal yr BP") 
  # add CONISS zones
  #geom_hline(yintercept = zones, col = "blue", lty = 1, alpha = 0.7) 
diat_plot

## Plot with diatom groups
diat_groups_plt <- core_counts_common %>% 
  mutate(group = plyr::mapvalues(taxa, from = nms_diat[,2], to = nms_diat[,3])) %>%
  group_by(depth, upper_age, lower_age) %>%
  mutate(sqrt_pc = sqrt(relative_abundance_percent),
         Norm_sqrt_pc=sqrt_pc/sum(sqrt_pc)*100) %>%
  ungroup() %>%
  mutate(group=factor(group)) %>%
  select(-sqrt_pc) 

levels(diat_groups_plt$group)
levels(diat_groups_plt$taxa)

## Plot the data
theme_set(theme_bw(base_size=16))
diat_plot <- ggplot(diat_groups_plt, aes(x = Norm_sqrt_pc, y = upper_age)) +
  geom_col_segsh() +
  #scale_y_reverse() +
  facet_abundanceh(vars(group), rotate_facet_labels = 70) +
  labs(x = "Relative abundance (%)", y = "Cal yr BP") +
  scale_x_continuous(breaks=seq(0, 100, by=20)) +
  scale_y_reverse(breaks=seq(0, 284000, by=20000)) +
  ggtitle("Fuquene diatom record (M1, F7 and F9)")
diat_plot
```

## Clean data and Estimate Principal Curves (PrC) of the F9 pollen core
```{r pollen data F9, echo=FALSE, warning=FALSE}
#Read in F9 pollen record
F9_pollen <- read.csv("data/Fuquene_F9_pollen.csv") %>%
  #rename(depth=ï..depth) %>% #rename extraneous column name  
  select(-c(contains("Lycopo") | contains("Tot.LocTot.100"))) %>%
  #select(-c(66,67,68,70)) %>% #exclude spores 
  rename(depth=ï..depth)

names(F9_pollen)

#this is to transform to tidy format, calculate % and subset more common species
pollen_long <- F9_pollen %>% 
  gather(key = taxa, value = count, -depth, -upper_age, -lower_age) %>%
  #mutate(taxa = plyr::mapvalues(taxa, from = changes[,1], to = changes$new_2)) %>%
  group_by(depth, taxa, upper_age, lower_age) %>%
  summarise(count = sum(count)) %>%
  filter(!count == "0" ) %>% #this is to remove empty samples (rows)
  filter(!upper_age==0.0) %>% #this is to drop extraneous ages
  ungroup() %>%
  group_by(depth) %>%
  mutate(relative_abundance_percent = count / sum(count) * 100) %>%
  ungroup()

range(pollen_long$upper_age)

# filter more abundant taxa; format need to be on long-wide format-->no spreaded 
core_common_taxa <- pollen_long %>%
  group_by(taxa) %>%
  summarise(max_rel_abund = max(relative_abundance_percent)) %>%
  filter(max_rel_abund >= 2) %>%
  arrange(max_rel_abund) %>%
  pull(taxa)

# select from initial table
core_counts_common_F9 <- pollen_long %>%
  filter(taxa %in% core_common_taxa) %>%
  mutate(taxa = factor(taxa, levels = core_common_taxa)) %>%
  arrange(taxa)

#make it wide--relative abundance
core_counts_wide_F9 <- core_counts_common_F9 %>%
  select(depth, upper_age, lower_age, taxa, relative_abundance_percent) %>%
  spread(key = taxa, value = relative_abundance_percent) %>%
  arrange(upper_age)

#make it wide--counts
core_counts_wide_F9 <- core_counts_common_F9 %>%
  select(depth, upper_age, lower_age, taxa, count) %>%
  spread(key = taxa, value = count) %>%
  arrange(upper_age)

# check age core ranges
range(core_counts_wide_F9$upper_age)

```

### Check temporal resolution of pollen F9 record
```{r}
mean(diff(core_counts_wide_F9$upper_age))
plot.ts(diff(core_counts_wide_F9$upper_age))
```

### Run and Plot PrC trends
```{r}
# remove agedepth columns for Hellinger transformation and bind back
agedepth <- core_counts_wide_F9[,names(core_counts_wide_F9) %in% c("depth", "upper_age", "lower_age")]
pollen <- core_counts_wide_F9[,!(names(core_counts_wide_F9) %in% c("upper_age", "lower_age", "depth"))]
pollen[is.na(pollen)] <- 0 #Replace NA (if any) by 0

# Transform data to Hellinger form
pollen_hell <- decostand(pollen, method="hellinger")

# Run Principal Curves and extract scores for then combining the resulting dataframe with agedepth
pollen.prc <- prcurve(pollen_hell, method = "ca", trace = TRUE, vary = TRUE, penalty = 1.4)
scrs_prc <- scores(pollen.prc, display = "curve")

PollenPrC <- cbind(agedepth, scrs_prc)

# Plot Pcurves with depth and ages
PollenPlot <- ggplot(PollenPrC, aes(x = upper_age, y = PrC)) +
  geom_line() + geom_point() +
  labs(y = "Pollen PrC", x = "Age (cal yr BP)", title = "") +
  ggtitle("Pollen PrC")
PollenPlot
```

##Clean data and estimate PrC of the Fuquene 7 pollen record
```{r pollen data F7, warning=FALSE}
#Read in F7 pollen record
F7_pollen <- read.csv("data/Fuquene_F7_pollen.csv", sep = ",") %>%
  #rename(depth=ï..depth) %>% #rename extraneous column name  
  select(-c(contains("Lycopo"))) %>%
  select(-c(115,116,117,118,119)) %>% #exclude secondary variables (tablets, influx factor, etc)
  rename(depth=ï..depth)

names(F7_pollen)
str(F7_pollen)

#this is to transform to tidy format, calculate % and subset more common species
pollen_long <- F7_pollen %>% 
  gather(key = taxa, value = count, -depth, -upper_age, -lower_age) %>%
  #mutate(taxa = plyr::mapvalues(taxa, from = changes[,1], to = changes$new_2)) %>%
  group_by(depth, taxa, upper_age, lower_age) %>%
  summarise(count = sum(count)) %>%
  filter(!count == "0" ) %>% #this is to remove empty samples (rows)
  filter(!upper_age==0.0) %>% #this is to drop extraneous ages
  ungroup() %>%
  group_by(depth) %>%
  mutate(relative_abundance_percent = count / sum(count) * 100) %>%
  ungroup()

range(pollen_long$upper_age) 

# filter more abundant taxa; format need to be on long-wide format-->no spreaded 
core_common_taxa <- pollen_long %>%
  group_by(taxa) %>%
  summarise(max_rel_abund = max(relative_abundance_percent)) %>%
  filter(max_rel_abund >= 2) %>%
  arrange(max_rel_abund) %>%
  pull(taxa)

# select from initial table
core_counts_common_F7 <- pollen_long %>%
  filter(taxa %in% core_common_taxa) %>%
  mutate(taxa = factor(taxa, levels = core_common_taxa)) %>%
  arrange(taxa)

#make it wide--relative abundance
core_counts_wide_F7 <- core_counts_common_F7 %>%
  select(depth, upper_age, lower_age, taxa, relative_abundance_percent) %>%
  spread(key = taxa, value = relative_abundance_percent) %>%
  arrange(upper_age)

#make it wide--counts
core_counts_wide_F7 <- core_counts_common_F7 %>%
  select(depth, upper_age, lower_age, taxa, count) %>%
  spread(key = taxa, value = count) %>%
  arrange(upper_age)

# check age core ranges
range(core_counts_wide_F7$upper_age)

```

## Clean data of the M1 pollen core
```{r pollen data M1, echo=FALSE, warning=FALSE}
M1_pollen <- read.csv("data/Fuquene_pollen_M1_counts.csv") %>%
    select(-c(contains("Lycopo") | contains("Carbones") | contains("concentration") | contains("Suma.total") |
                contains("Pollen.spores") | contains("Huevo"))) %>%
    rename(depth=ï..depth) #rename extraneous column name 


# here drop out algae and spores
names(M1_pollen)
#drop <- c(85:119) #indexes where spores and algae are

# check ages ranges
range(M1_pollen$upper_age)

#this is to transform to tidy format, calculate % and subset more common species
pollen_long <- M1_pollen %>% 
  gather(key = taxa, value = count, -depth, -upper_age, -lower_age) %>%
  #mutate(taxa = plyr::mapvalues(taxa, from = changes[,1], to = changes$new_2)) %>%
  group_by(depth, taxa, upper_age, lower_age) %>%
  summarise(count = sum(count)) %>%
  filter(!count == "0" ) %>% #this is to remove empty samples (rows)
  filter(!upper_age==0.0) %>% #this is to drop extraneous ages
  ungroup() %>%
  group_by(depth) %>%
  mutate(relative_abundance_percent = count / sum(count) * 100) %>%
  ungroup()

# filter more abundant taxa; format need to be on long-wide format-->no spreaded 
core_common_taxa <- pollen_long %>%
  group_by(taxa) %>%
  summarise(max_rel_abund = max(relative_abundance_percent)) %>%
  filter(max_rel_abund >= 2) %>%
  arrange(max_rel_abund) %>%
  pull(taxa)

# select from initial table
core_counts_common_M1 <- pollen_long %>%
  filter(taxa %in% core_common_taxa) %>%
  mutate(taxa = factor(taxa, levels = core_common_taxa)) %>%
  arrange(taxa)

#make it wide--relative abundance
core_counts_wide_M1 <- core_counts_common_M1 %>%
  select(depth, upper_age, lower_age, taxa, relative_abundance_percent) %>%
  spread(key = taxa, value = relative_abundance_percent) 

#make it wide--counts
core_counts_wide_M1 <- core_counts_common_M1 %>%
  select(depth, upper_age, lower_age, taxa, count) %>%
  spread(key = taxa, value = count) 

```

## Join M1, F7 and F9 records by common taxa names (columns)
```{r join pollen records, echo=FALSE, message=FALSE, warning=FALSE}
#combine cores (join's analogue package function)
df <- analogue::join(core_counts_wide_M1, core_counts_wide_F7, core_counts_wide_F9, verbose = TRUE)

#check NA in the list and name the list
listnans <- lapply(df, function(x) sum(is.na(x)))
names(df) <- c("M1", "F7", "F9")

# extract merged cores and sort by age
merged <- plyr::ldply(df, data.frame)
# merged <- merged[,-1] #remove .id variable

pollen_M1_F7_F9 <- merged[order(merged$upper_age),] %>% #arrange in increasing depth
                  rename(core=.id)

# remove extraneous samples with negative ages
pollen_M1_F7_F9 <- pollen_M1_F7_F9 %>%
  filter(upper_age > -70) %>%
  filter(!lower_age==0.0) #this is to drop extraneous ages

# write results
write.csv(pollen_M1_F7_F9, "outputs/pollen_M1_F7_F9_counts_2RA.csv")
```

## Stratigraphic plot pollen cores M1, F7 and F9
```{r}
# Gather dataset
pollen_long_M1_F7_F9 <- pollen_M1_F7_F9 %>% 
  gather(key = taxa, value = relative_abundance_percent, -depth, -upper_age, -lower_age, -core) 

# Plot  
pollen_plot <- ggplot(pollen_long_M1_F7_F9, aes(x = relative_abundance_percent, y = upper_age)) +
  geom_col_segsh() +
  scale_y_reverse() +
  facet_abundanceh(vars(taxa)) +
  labs(x = "Relative abundance (%)", y = "Cal yr BP")
  # add CONISS zones
  #geom_hline(yintercept = zones, col = "blue", lty = 1, alpha = 0.7) 
pollen_plot

```

## Composite pollen M1, F7 & F9 cores. NOTE: There are two datasets: 2% and 5% RA with their corresponding taxa grouping names

```{r}
## Read in change nms table
nms_pollen <- read.csv("data/nms_changes_pollen_M1_F7_F9_2RA.csv", sep = ",")
head(nms_pollen)
#colnames(nms_pollen)[1] <- "taxa"

## Change pollen names and groups
pollen_M1_F7_F9 <- read.csv("outputs/pollen_M1_F7_F9_counts_2RA.csv")[-1] %>% #remove column core
  gather(key = taxa, value = count, -depth, -upper_age, -lower_age, -core) %>%
  mutate(taxa = plyr::mapvalues(taxa, from = nms_pollen[,1], to = nms_pollen$new)) %>%
  mutate(group = plyr::mapvalues(taxa, from = nms_pollen[,2], to = nms_pollen$habitat)) %>%
  mutate(habitat = plyr::mapvalues(taxa, from = nms_pollen[,2], to = nms_pollen$aquatic_habitat)) %>%
  #mutate(group = replace(group, str_detect(group, "Botryococcus"), "Algae")) %>% #something weird with Botryococcus
   #mutate(habitat = replace(habitat, str_detect(habitat, "Botryococcus"), "submerged")) %>% #something weird with Botryococcus
  group_by(depth, upper_age, lower_age) %>%
  mutate(relative_abundance_percent = count / sum(count) * 100,
         sqrt_pc = sqrt(relative_abundance_percent),
         Norm_sqrt_pc=sqrt_pc/sum(sqrt_pc)*100) %>%
  ungroup() %>%
  mutate(group=factor(group)) %>%
  mutate(habitat=factor(habitat)) %>%
  select(-sqrt_pc) 

levels(pollen_M1_F7_F9$group)
levels(pollen_M1_F7_F9$habitat)

## Plot the data
theme_set(theme_bw(base_size=16))
pollen_plot <- ggplot(pollen_M1_F7_F9, aes(x = Norm_sqrt_pc, y = upper_age, colour=habitat)) +
  geom_col_segsh() +
  #scale_y_reverse() +
  facet_abundanceh(vars(group), grouping = vars(habitat), rotate_facet_labels = 70) +
  labs(x = "Relative abundance (%)", y = "Cal yr BP") +
  scale_x_continuous(breaks=seq(0, 100, by=20)) +
  scale_y_reverse(breaks=seq(0, 284000, by=20000)) +
  ggtitle("Fuquene composite pollen record (M1, F7 and F9)")
pollen_plot

ggsave("outputs/pollen_composite_groups.png",
       plot = last_plot() ,
       width = 10,
       height=8,
       units="in",
       dpi = 300)

## Spread using pivot_wider--> doesn't work for some reason
# poll_wide <- pollen_M1_F7_F9 %>% 
#   pivot_wider(id_cols=c(depth, upper_age, lower_age), 
#   names_from=c("taxa", "group", "habitat"), values_from=c(count,relative_abundance_percent), values_fill=0)

## Spread using pivot_wider
poll_wide <- pollen_M1_F7_F9 %>%
  droplevels() %>%
  select(depth, upper_age, lower_age, taxa, relative_abundance_percent) %>%
  spread(key = taxa, value = relative_abundance_percent) %>%
  arrange(upper_age) #sort by increasing time
  
## Separate aquatics and non-aquatics pollen
aq_floating <- pollen_M1_F7_F9 %>%
  filter(str_detect(habitat, "floating")) %>%
  droplevels() %>%
  group_by(depth) %>%
  mutate(total_sample = sum(count),
         relative_abundance_percent = count / sum(count) * 100) %>%
  filter(!total_sample==0) %>%
  ungroup() %>%
  select(depth, upper_age, lower_age, taxa, relative_abundance_percent) %>%
  spread(key = taxa, value = relative_abundance_percent) %>%
  arrange(upper_age) 
  
aq_emergent <- pollen_M1_F7_F9 %>%
  filter(str_detect(habitat, "emergent")) %>%
  droplevels() %>%
  group_by(depth) %>%
  mutate(total_sample = sum(count),
         relative_abundance_percent = count / sum(count) * 100) %>%
  filter(!total_sample==0) %>%
  ungroup() %>%
  select(depth, upper_age, lower_age, taxa, relative_abundance_percent) %>%
  spread(key = taxa, value = relative_abundance_percent) %>%
  arrange(upper_age) #sort by increasing time

aq_submerged <- pollen_M1_F7_F9 %>%
  filter(str_detect(habitat, "submerged")) %>%
  droplevels() %>%
  group_by(depth) %>%
  mutate(total_sample = sum(count),
         relative_abundance_percent = count / sum(count) * 100) %>%
  filter(!total_sample==0) %>%
  ungroup() %>%
  select(depth, upper_age, lower_age, taxa, relative_abundance_percent) %>%
  spread(key = taxa, value = relative_abundance_percent) %>%
  arrange(upper_age) #sort by increasing time

terrestrial <- pollen_M1_F7_F9 %>%
  filter(str_detect(habitat, "terrestrial")) %>%
  droplevels() %>%
  group_by(depth) %>%
  mutate(total_sample = sum(count),
         relative_abundance_percent = count / sum(count) * 100) %>%
  filter(!total_sample==0) %>%
  ungroup() %>%
  select(depth, upper_age, lower_age, taxa, relative_abundance_percent) %>%
  spread(key = taxa, value = relative_abundance_percent) %>%
  arrange(upper_age) #sort by increasing time

```

## Check temporal resolution of composite pollen record
```{r}
pollen_M1_F7_F9_wide <- read.csv("outputs/pollen_M1_F7_F9_counts_5RA.csv")[-1]

median(diff(pollen_M1_F7_F9_wide$upper_age))
plot.ts(diff(pollen_M1_F7_F9_wide$upper_age))
```

### Run and Plot PrC trends pollen groups and diatoms (composite Fuquene record M1, F7, F9)
```{r}
pollen_df <- terrestrial

# remove agedepth columns for Hellinger transformation and bind back
agedepth <- pollen_df[,names(pollen_df) %in% c("core","depth", "upper_age", "lower_age")]
pollen <- pollen_df[,!(names(pollen_df) %in% c("core","upper_age", "lower_age", "depth"))]

# Transform data to Hellinger form
pollen_hell <- decostand(pollen, method="hellinger")
pollen_hell <- pollen_hell[rowSums(pollen_hell)>0,]

test <- as.matrix(rowSums(pollen_hell))

# Run Principal Curves and extract scores for then combining the resulting dataframe with agedepth
# pollen.prc <- prcurve(pollen_hell, method = "ca", trace = TRUE, vary = TRUE, penalty = 1.4,
#                       smoother = smoothGAM, bs="cr", family = mgcv::betar())
pollen.prc <- prcurve(pollen_hell, method = "ca", trace = TRUE, vary = TRUE, penalty = 1.4)

scrs_prc <- scores(pollen.prc, display = "curve")


PollenPrC <- merge(agedepth, scrs_prc, by=0) 
#PollenPrC <- cbind(agedepth, scrs_prc)

# Plot Pcurves with depth and ages
PollenPlot <- ggplot(PollenPrC, aes(x = upper_age, y = PrC)) +
  geom_line() + 
  geom_smooth() +
  labs(y = "Pollen PrC", x = "Age (cal yr BP)", title = "") +
  ggtitle("Pollen PrC")
PollenPlot

## save PrC for each pollen group
aq_floating_prc <- PollenPrC
aq_floating_prc$proxy <- "aq_floating"
aq_emergent_prc <- PollenPrC
aq_emergent_prc$proxy <- "aq_emergent"
aq_submerged_prc <- PollenPrC #not working
aq_submerged_prc$proxy <- "aq_emergent"
poll_terrestrial_prc <- PollenPrC
poll_terrestrial_prc$proxy <- "terrestrial"

# Combine PrC datasets
prc_df <- aq_floating_prc %>%
  bind_rows(aq_emergent_prc,poll_terrestrial_prc) %>%
  select(-c(1)) %>%
  bind_rows(diatomsPrC)

# Plot Pcurves with depth and ages
PrC_plot <- ggplot(prc_df, aes(x = upper_age, y = PrC)) +
  geom_line() + 
  facet_wrap(~proxy, ncol=1,scales = "free_y")+
  geom_smooth() +
  labs(y = "Principal curve", x = "Age (cal yr BP)") +
  scale_x_continuous(breaks=seq(0, 284000, by=40000)) +
  ggtitle("Fuquene aquatic and terrestrial trends")
PrC_plot

ggsave("outputs/prc_composite_record.png",
       plot = last_plot() ,
       width = 10,
       height=8,
       units="in",
       dpi = 300)

```



## Geochemical and gran size datasets
```{r}
#Read in geochemistry 
F9_geochem <- read.csv("data/Fuquene_F9_geochem.csv") %>%
  #rename(depth=ï..depth) %>%
  rename(TIC_percent=X..TIC) %>%
  rename(N_percent=wt..N) %>%
  rename(C_percent=wt..C) %>%
  rename(TOC_percent=wt..TOC) %>%
  rename(TC_TN=TC.TN) %>%
  rename(d13C=d13C..permil..vs.VPDB.)

names(F9_geochem)
 
#check median temporal resolution
median(diff(F9_geochem$upper_age))
plot.ts(diff(F9_geochem$upper_age))

#Read in grain size 
F9_grainsize <- read.csv("data/Fuquene_F9_grainsize.csv") %>%
  rename(depth=depth..cm.) %>%
  rename(upper_age=ï..upper_age)

#check median temporal resolution
median(diff(F9_grainsize$upper_age))
plot.ts(diff(F9_grainsize$upper_age))
```


```{r}
### Interpolation to the coarser dataset: geochemistry

LOI375_i <- as.data.frame(approx(F9_grainsize$upper_age, F9_grainsize$LOI.375, F9_geochem$upper_age)$y)
LOI375_i$age <- F9_geochem$upper_age
colnames(LOI375_i) <- c("LOI375", "age")

LOI375_i$sand <- approx(F9_grainsize$upper_age, F9_grainsize$EM1, F9_geochem$upper_age)$y
LOI375_i$coarsesilt <- approx(F9_grainsize$upper_age, F9_grainsize$EM2, F9_geochem$upper_age)$y
LOI375_i$finesilt <- approx(F9_grainsize$upper_age, F9_grainsize$EM3, F9_geochem$upper_age)$y
LOI375_i$clay <- approx(F9_grainsize$upper_age, F9_grainsize$EM4, F9_geochem$upper_age)$y

F9_geochem_grainsize_i <- LOI375_i

head(F9_geochem_grainsize_i)
median(diff(F9_geochem_grainsize_i$age))

# test some temporal variations
plot.ts(F9_geochem_grainsize_i$age, F9_geochem_grainsize_i[,3])

# Cbind the two dataframes
F9_geochem_grainsize_int <- cbind(F9_geochem[,c(1,3:ncol(F9_geochem))], F9_geochem_grainsize_i)

# reorder columns and change upper age name
F9_geochem_grainsize_i <- F9_geochem_grainsize_int[,c(1,10,2,3,4,5,6,7,8,9,11,12,13,14)]
colnames(F9_geochem_grainsize_i)[2] <- "upper_age"

# Save the dataset
write.csv(F9_geochem_grainsize_i, "outputs/F9_geochem_grainsize_i.csv")
```


## Hierarchical Generalized Additive Models (HGAM) -- **Synchronous model**
In this step we model, first, diatom and pollen assemblages using HGAM and then calculate average rate of change at assemblage-level to assess the timing in the start of rapid change in the time-series, and test comparable rates of change between aquatic and terrestrial ecosystems.

By obtaining derivative-based values of the diatom, terrestrial pollen, and agropastoralism time series we obtain regular time intervals at XX-year resolution (median between diatom and pollen records) and hence comparable--same time steps-- for fitting the synchronous and asynchronous models. 

We fit model S HGAM (Pedersen et al., 2019): group-level smoothness between groups (spp) without a global smooth while allowing different willingness to not assume any shape among species for each assemblage.

### Diatom assemblages
This chunk is reproducible for pollen

```{r HGAM diatoms}
#Prepare the data
agedepth <- F_diatoms[, names(F_diatoms) %in% c("depth", "upper_age", "lower_age", "core")] 
diat <- F_diatoms[, !names(F_diatoms) %in% c("depth", "upper_age", "lower_age", "core")]
diat[is.na(diat)] <- 0

#Select most common species 
criteria <- 0.2 #% of the total samples

n.occur <- apply(diat>0, 2, sum)
diat_red <- diat[, n.occur > (dim(diat)[1])*criteria] #
diatoms <- cbind(agedepth, diat_red)

#this is to transform to tidy format, calculate % and subset more common species
diat_data <- diatoms %>% 
  gather(key = taxa, value = count, -depth, -upper_age, -lower_age, -core) %>%
  mutate(taxa = plyr::mapvalues(taxa, from = nms_diat[,1], to = nms_diat[,2])) %>%
  group_by(depth) %>%
  mutate(total_sample = sum(count)) %>% 
  filter(!total_sample == "0") %>% #this is to remove empty samples
  mutate(log_total_counts = log10(total_sample+1)) %>%
  mutate(relative_abundance_percent = count / sum(count) * 100) %>%
  mutate(negAge = -upper_age) %>%
  #mutate(AgeCE = upper_age*(-1)+1950) %>%
  #filter(AgeCE >= "0") %>%
  mutate(elapsedTime = round(abs(upper_age - lower_age),0)) %>%
  ungroup() %>%
  filter(!is.na(elapsedTime)) %>%
  mutate(spp = factor(taxa)) 

levels(diat_data$spp)

#model S HGAM : similar smootheness between groups (spp) without global smooth 
set.seed(10) #set a seed so this is repeatable
diatom_gam_S <- gam(count ~ s(negAge, spp, k=20, bs="fs") + offset(log_total_counts),
                    weights = elapsedTime/mean(elapsedTime),
                    data=diat_data, family = nb, #places notes at the deciles of sample ages
                    method = "REML")

summary(diatom_gam_S)
gam.check(diatom_gam_S)
draw(diatom_gam_S)

#model I HGAM: different smootheness for each taxa without global smooth
diatom_gam_I<- gam(count ~ s(negAge, by=spp, k=20, bs="fs") +
                     s(spp, bs="re") + offset(log_total_counts),
                   weights = elapsedTime/mean(elapsedTime),
                   data=diat_data, family = nb, #places notes at the deciles of sample ages
                   method = "REML")

gam.check(diatom_gam_I)
draw(diatom_gam_I)

#Compare different model fits using AIC
AIC_table <- AIC(diatom_gam_S, diatom_gam_I)%>%
  rownames_to_column(var= "Model")%>%
  mutate(data_source = rep(c("diatom_data")))%>%
  group_by(data_source)%>%
  mutate(deltaAIC = AIC - min(AIC))%>%
  ungroup()%>%
  dplyr::select(-data_source)%>%
  mutate_at(.vars = vars(df,AIC, deltaAIC), 
            .funs = funs(round,.args = list(digits=0)))

#Create synthetic data to predict over a range of ages
diat_plot_data <- with(diat_data, as_tibble(expand.grid(negAge = seq(min(diat_data$negAge), max(diat_data$negAge)),
                                                        spp = factor(levels(diat_data$spp)),
                                                        log_total_counts = mean(log_total_counts))))

diat_modS_fit <- predict(diatom_gam_S,
                         newdata = diat_plot_data,
                         se.fit = TRUE)

diat_modI_fit <- predict(diatom_gam_I,
                         newdata = diat_plot_data,
                         se.fit = TRUE)

#non-shared trends
diat_plot_data$modS_fit <- as.numeric(diat_modS_fit$fit)
diat_plot_data$modI_fit <- as.numeric(diat_modI_fit$fit)

# comparing non-shared trends
diat_plot_data <- gather(diat_plot_data, key=model, value=fit, modS_fit, modI_fit)

diat_plot_data <- mutate(diat_plot_data, se= c(as.numeric(diat_modS_fit$se.fit),
                                               as.numeric(diat_modI_fit$se.fit)),
                         upper = exp(fit + (2 * se)),
                         lower = exp(fit - (2 * se)),
                         fit   = exp(fit))

# For only one model
# diat_plot_data <- gather(diat_plot_data, key=model, value=fit, modI_fit)
# diat_plot_data <- mutate(diat_plot_data, se= c(as.numeric(diat_modI_fit$se.fit)),
#                          upper = exp(fit + (2 * se)),
#                          lower = exp(fit - (2 * se)),
#                          fit   = exp(fit))
# diat_plot_model_labels <- paste("Model", c("I"))

#Plot the model output for non-shared trends, with means plus standard deviations for each model.
diat_plot_model_labels <- paste("Model", c("S", "I"))
diat_plot_model_labels <- factor(diat_plot_model_labels, levels = diat_plot_model_labels)

#non-shared trends
theme_set(theme_bw())
theme_update(panel.grid = element_blank())

diat_plot <- ggplot(diat_plot_data) +
  facet_wrap(~spp, nrow = 4,scales = "free_y")+
  geom_ribbon(aes(x=negAge,
                  ymin = lower,
                  ymax = upper,
                  fill = model),
              alpha=0.2)+
  geom_point(data= diat_data, aes(x = negAge, y = count), size=0.06) +
  geom_line(aes(x = negAge, y = fit, color = model))+
  labs(y = "Absolute counts", x = "Age (cal yr BP)") +
  scale_fill_brewer(name = "", palette = "Dark2",
                    labels = diat_plot_model_labels) +
  scale_colour_brewer(name = "",
                      palette = "Dark2", labels = diat_plot_model_labels)+
  theme(legend.position = "top",
        strip.text = element_text(size=10))

diat_plot

## save model results for later use
write.csv(diat_plot_data, "outputs/diatoms-HGAMs-fitted-values.csv", row.names = FALSE)

```

##Derivatives and posterior distribution simulation
```{r diatom derivatives}
# Eric's code
#Function for calculating first derivatives of time series given a before,
#after, and delta step size
calc_1st_deriv = function(fit_before, fit_after,delta) {
  (fit_after-fit_before)/(2*delta)
}

set.seed(10) #set a seed so this is repeatable
n_sims = 250

n_length = 200

years <- seq(min(diat_plot_data$negAge),
             max(diat_plot_data$negAge),
             length.out = n_length)

diff(years)
#model <- diatom_gam_S

model <- diatom_gam_I

#pred <- diat_modS_fit
pred <- diat_modI_fit

# Generate multivariate normal simulations of model coefficients
random_coefs <- t(rmvn(n_sims, mu = coef(model),V = vcov(model)))

confint_sims <- crossing(spp=unique(diat_plot_data$spp),
                         negAge = seq(min(diat_plot_data$negAge),
                                      max(diat_plot_data$negAge),
                                      length.out = n_length),
                         log_total_counts=0)

map_pred_sims <- predict(model,
                         confint_sims,
                         type = "lpmatrix") %*% random_coefs %>%
  as_data_frame() %>%
  bind_cols(confint_sims)%>%
  gather(key = simulation, value = pred, -negAge, -log_total_counts,-spp)


#specifying the step size for numerical derivative calculations
delta = 0.01

#calculating the predicted value for the current year plus delta
step_ahead_fits = confint_sims %>%
  mutate(negAge = negAge+delta)%>%
  predict(model, 
          ., type = "lpmatrix") %*% random_coefs 


#calculating the predicted value for the current year minus delta
step_behind_fits = confint_sims %>%
  mutate(negAge = negAge-delta)%>%
  predict(model,
          ., type = "lpmatrix") %*% random_coefs 


#using the predicted values for year plus and minus delta to calculate
#derivatives for each species for each simulation
derivs <- calc_1st_deriv(step_behind_fits,step_ahead_fits,delta = delta)%>%
  as_data_frame()%>%
  bind_cols(confint_sims)%>%
  gather(key = simulation,value = deriv, -spp,-negAge, -log_total_counts)

#Creating summaries of derivatives for each simulation for each year
deriv_summaries <- derivs %>%
  group_by(negAge,simulation)%>%
  summarize(deriv_mean = mean(deriv),
            deriv_sd = sd(deriv))%>%
  group_by(negAge)%>% #turning derivative summaries into 95% confidence intervals
  select(-simulation)%>%
  summarize_all(.funs = list(lower = ~quantile(.,probs = 0.025),
                             upper = ~quantile(.,probs = 0.975),
                             med   = ~quantile(.,probs = 0.5)))

#Plotting mean rate of change plus the 95% CI
mean_plot <- deriv_summaries %>%
  ggplot(aes(x = negAge, 
             y = deriv_mean_med, 
             ymin = deriv_mean_lower,
             ymax = deriv_mean_upper))+
  geom_ribbon(fill="grey")+
  geom_line()+
  geom_hline(yintercept = 0, linetype=2) +
  scale_y_continuous("")+
  xlab("Cal years BP") +
  theme_bw()
mean_plot 

#Plotting standard deviation of rate of change plus the 95% CI
sd_plot <- deriv_summaries %>%
  ggplot(aes(x = negAge, 
             y = deriv_sd_med, 
             ymin=deriv_sd_lower,
             ymax=deriv_sd_upper))+
  geom_ribbon(fill="grey")+
  geom_line()+
  geom_hline(yintercept = 0, linetype=2) +
  scale_y_continuous("")+
  xlab("Cal years BP") +
  theme_bw()
sd_plot


## save derivative summaries for later use
write.csv(deriv_summaries, "outputs/diatom-derivatives.csv", row.names = FALSE)
```

### Pollen HGAM
```{r HGAM pollen}
## Read in change nms table
nms_pollen <- read.csv("data/nms_changes_pollen_M1_F7_F9_2RA.csv", sep = ",")
head(nms_pollen)

#Read the pollen data
pollen_wide<- read.csv("outputs/pollen_M1_F7_F9_counts_2RA.csv")[-1]

agedepth <- pollen_wide[, names(pollen_wide) %in% c("depth", "upper_age", "lower_age", "core")] 
pollen_wide <- pollen_wide[, !names(pollen_wide) %in% c("depth", "upper_age", "lower_age", "core")]
pollen_wide[is.na(pollen_wide)] <- 0

#Select most common species 
criteria <- 0.2 #% of the total samples

n.occur <- apply(pollen_wide>0, 2, sum)
pollen_red <- pollen_wide[, n.occur > (dim(pollen_wide)[1])*criteria] #
pollen <- cbind(agedepth, pollen_red)

## Change pollen names and groups (>5% RA in at least one sample)
pollen_longdata <- pollen %>% #remove column core
  gather(key = taxa, value = count, -depth, -upper_age, -lower_age, -core) %>%
  mutate(taxa = plyr::mapvalues(taxa, from = nms_pollen[,1], to = nms_pollen$new)) %>%
  mutate(habitat = plyr::mapvalues(taxa, from = nms_pollen[,2], to = nms_pollen$habitat)) %>%
  mutate(group = plyr::mapvalues(taxa, from = nms_pollen[,2], to = nms_pollen$aquatic_habitat)) %>%
  group_by(depth) %>%
  mutate(total_sample = sum(count)) %>% 
  filter(!total_sample == "0") %>% #this is to remove empty samples
  mutate(log_total_counts = log10(total_sample+1)) %>%
  mutate(relative_abundance_percent = count / sum(count) * 100) %>%
  mutate(negAge = -upper_age) %>%
  mutate(elapsedTime = round(abs(upper_age - lower_age),0)) %>%
  filter(!is.na(elapsedTime)) %>%
  mutate(spp = factor(taxa)) %>%
  mutate(habitat=factor(habitat)) %>%
  mutate(group=factor(group)) %>%
  ungroup() 

levels(pollen_longdata$spp)
levels(pollen_longdata$habitat)
levels(pollen_longdata$group)

## Separate aquatics and non-aquatics pollen
aq_pollen <- pollen_longdata %>%
  filter(str_detect(habitat, "Aquatic")) %>%
  droplevels() %>%
  arrange(upper_age) 

aq_floating <- pollen_longdata %>%
  filter(str_detect(group, "floating")) %>%
  droplevels() %>%
  arrange(upper_age) 

aq_emergent <- pollen_longdata %>%
  filter(str_detect(group, "emergent")) %>%
  droplevels() %>%
  arrange(upper_age)

aq_submerged <- pollen_longdata %>%
  filter(str_detect(group, "submerged")) %>%
  droplevels() %>%
  arrange(upper_age)

terrestrial <- pollen_longdata %>%
  filter(str_detect(group, "terrestrial")) %>%
  droplevels() %>%
  arrange(upper_age)

# Set pollen dataset to model
pollen_data <- aq_submerged
levels(pollen_data$spp)

#model S HGAM : similar smootheness between groups (spp) without global smooth 
set.seed(10) #set a seed so this is repeatable
pollen_gam_S <- gam(count ~ s(negAge, spp, k=20, bs="fs") + offset(log_total_counts),
                    weights = elapsedTime/mean(elapsedTime),
                    data=pollen_data, family = nb, 
                    method = "REML")

summary(pollen_gam_S)
gam.check(pollen_gam_S)
draw(pollen_gam_S)

#model I HGAM: different smootheness for each taxa without global smooth
pollen_gam_I<- gam(count ~ s(negAge, by=spp, k=20, bs="fs") +
                     s(spp, bs="re") + offset(log_total_counts),
                   weights = elapsedTime/mean(elapsedTime),
                   data=pollen_data, family = nb, #places notes at the deciles of sample ages
                   method = "REML")

gam.check(pollen_gam_I)
draw(pollen_gam_I)

#Compare different model fits using AIC
AIC_table <- AIC(pollen_gam_S, pollen_gam_I)%>%
  rownames_to_column(var= "Model")%>%
  mutate(data_source = rep(c("diatom_data")))%>%
  group_by(data_source)%>%
  mutate(deltaAIC = AIC - min(AIC))%>%
  ungroup()%>%
  dplyr::select(-data_source)%>%
  mutate_at(.vars = vars(df,AIC, deltaAIC), 
            .funs = funs(round,.args = list(digits=0)))

AIC_table

## Here the synthetic data to predict should be over the range of diatom ages to get the same ages for the synchronous/asynchronous model

#Create synthetic data to predict over a range of ages: here match with diatom samples
pollen_plot_data <- with(pollen_data, as_tibble(expand.grid(negAge = seq(min(diat_data$negAge), max(diat_data$negAge)),
                                                        spp = factor(levels(pollen_data$spp)),
                                                        log_total_counts = mean(log_total_counts))))


pollen_modS_fit <- predict(pollen_gam_S, 
                         newdata = pollen_plot_data,
                         se.fit = TRUE)

pollen_modI_fit <- predict(pollen_gam_I,
                         newdata = pollen_plot_data,
                         se.fit = TRUE)

#non-shared trends
pollen_plot_data$modS_fit <- as.numeric(pollen_modS_fit$fit)
pollen_plot_data$modI_fit <- as.numeric(pollen_modI_fit$fit)

# comparing non-shared trends
pollen_plot_data <- gather(pollen_plot_data, key=model, value=fit, modS_fit, modI_fit)

pollen_plot_data <- mutate(pollen_plot_data, se= c(as.numeric(pollen_modS_fit$se.fit),
                                               as.numeric(pollen_modI_fit$se.fit)),
                         upper = exp(fit + (2 * se)),
                         lower = exp(fit - (2 * se)),
                         fit   = exp(fit))


#Plot the model output for non-shared trends, with means plus standard deviations for each model.
pollen_plot_model_labels <- paste("Model", c("S", "I"))
pollen_plot_model_labels <- factor(pollen_plot_model_labels, levels = pollen_plot_model_labels)

#non-shared trends
theme_set(theme_bw())
theme_update(panel.grid = element_blank())

pollen_plot <- ggplot(pollen_plot_data) +
  facet_wrap(~spp, nrow = 4,scales = "free_y")+
  geom_ribbon(aes(x=negAge,
                  ymin = lower,
                  ymax = upper,
                  fill = model),
              alpha=0.2)+
  geom_point(data= pollen_data, aes(x = negAge, y = count), size=0.06) +
  geom_line(aes(x = negAge, y = fit, color = model))+
  labs(y = "Absolute counts", x = "Age (cal yr BP)") +
  scale_fill_brewer(name = "", palette = "Dark2",
                    labels = pollen_plot_model_labels) +
  scale_colour_brewer(name = "",
                      palette = "Dark2", labels = pollen_plot_model_labels)+
  theme(legend.position = "top",
        strip.text = element_text(size=10))

pollen_plot

ggsave("outputs/pollen_plot.png",
       plot = pollen_plot ,
       width = 10,
       height=8,
       units="in",
       dpi = 300)


## save model results for later use
write.csv(pollen_plot_data, "outputs/pollen-emergent-HGAMs-fitted-values.csv", row.names = FALSE)
```


```{r pollen derivatives}
# Eric's code
#Function for calculating first derivatives of time series given a before,
#after, and delta step size
calc_1st_deriv = function(fit_before, fit_after,delta) {
  (fit_after-fit_before)/(2*delta)
}

set.seed(10) #set a seed so this is repeatable
n_sims = 250

n_length = 200

years <- seq(min(pollen_plot_data$negAge),
             max(pollen_plot_data$negAge),
             length.out = n_length)

diff(years)
model <- pollen_gam_S
model <- pollen_gam_I

pred <- pollen_modS_fit
pred <- pollen_modI_fit

# Generate multivariate normal simulations of model coefficients
random_coefs <- t(rmvn(n_sims, mu = coef(model),V = vcov(model)))

confint_sims <- crossing(spp=unique(pollen_plot_data$spp),
                         negAge = seq(min(pollen_plot_data$negAge),
                                      max(pollen_plot_data$negAge),
                                      length.out = n_length),
                         log_total_counts=0)

map_pred_sims <- predict(model,
                         confint_sims,
                         type = "lpmatrix") %*% random_coefs %>%
  as_data_frame() %>%
  bind_cols(confint_sims)%>%
  gather(key = simulation, value = pred, -negAge, -log_total_counts,-spp)


#specifying the step size for numerical derivative calculations
delta = 0.01

#calculating the predicted value for the current year plus delta
step_ahead_fits = confint_sims %>%
  mutate(negAge = negAge+delta)%>%
  predict(model, 
          ., type = "lpmatrix") %*% random_coefs 


#calculating the predicted value for the current year minus delta
step_behind_fits = confint_sims %>%
  mutate(negAge = negAge-delta)%>%
  predict(model,
          ., type = "lpmatrix") %*% random_coefs 


#using the predicted values for year plus and minus delta to calculate
#derivatives for each species for each simulation
derivs <- calc_1st_deriv(step_behind_fits,step_ahead_fits,delta = delta)%>%
  as_data_frame()%>%
  bind_cols(confint_sims)%>%
  gather(key = simulation,value = deriv, -spp,-negAge, -log_total_counts)

#Creating summaries of derivatives for each simulation for each year
deriv_summaries <- derivs %>%
  group_by(negAge,simulation)%>%
  summarize(deriv_mean = mean(deriv),
            deriv_sd = sd(deriv))%>%
  group_by(negAge)%>% #turning derivative summaries into 95% confidence intervals
  select(-simulation)%>%
  summarize_all(.funs = list(lower = ~quantile(.,probs = 0.025),
                             upper = ~quantile(.,probs = 0.975),
                             med   = ~quantile(.,probs = 0.5)))

#Plotting mean rate of change plus the 95% CI
mean_plot <- deriv_summaries %>%
  ggplot(aes(x = negAge, 
             y = deriv_mean_med, 
             ymin = deriv_mean_lower,
             ymax = deriv_mean_upper))+
  geom_ribbon(fill="grey")+
  geom_line()+
  geom_hline(yintercept = 0, linetype=2) +
  scale_y_continuous("")+
  xlab("Cal years BP") +
  theme_bw()
mean_plot 

#Plotting standard deviation of rate of change plus the 95% CI
sd_plot <- deriv_summaries %>%
  ggplot(aes(x = negAge, 
             y = deriv_sd_med, 
             ymin=deriv_sd_lower,
             ymax=deriv_sd_upper))+
  geom_ribbon(fill="grey")+
  geom_line()+
  geom_hline(yintercept = 0, linetype=2) +
  scale_y_continuous("")+
  xlab("Cal years BP") +
  theme_bw()
sd_plot

## save derivative summaries for later use
write.csv(deriv_summaries, "outputs/pollen-aquatic-derivatives.csv", row.names = FALSE)
```

### Geochemistry and grainsize HGAM
```{r HGAM grain size and geochemistry}
## Read in interpolated data
F9_geochem_grainsize <- read.csv("outputs/F9_geochem_grainsize_i.csv", sep = ",")[-1] 

# Prepare data for modeling: grainsize
grainsize_long <- F9_geochem_grainsize %>%
  select(c(1,2,3,10,11,12,13,14)) %>%
  gather(key = element, value = value, -depth, -upper_age, -lower_age) %>%
  mutate(negAge = -upper_age) %>%
  mutate(elapsedTime = round(abs(upper_age - lower_age),0)) %>%
  filter(elapsedTime < 40000) %>%
  filter(!is.na(as.numeric(value))) %>%
  filter(!is.na(elapsedTime)) %>%
  mutate(element = factor(element)) %>%
  mutate(value_raw=value) %>%
  mutate_at(vars(value), sqrt) %>% #
  rename(value_sqrt=value)

levels(grainsize_long$element)
range(grainsize_long$elapsedTime)

## Quick plot the trends
grainsize_plot <- ggplot(grainsize_long, aes(x = value_raw, y = upper_age)) +
  geom_lineh() +
  #geom_smooth()+
  scale_y_reverse() +
  geom_point() +
  facet_geochem_gridh(vars(element)) +
  labs(x = NULL) +
  labs(y = NULL)
#ggtitle("XRF")
grainsize_plot

# Prepare data for modeling: geochem
geochem_long <- F9_geochem_grainsize %>%
  select(c(1,2,3,4,5,6,7,8,9)) %>%
  gather(key = element, value = value, -depth, -upper_age, -lower_age) %>%
  mutate(negAge = -upper_age) %>%
  mutate(elapsedTime = round(abs(upper_age - lower_age),0)) %>%
  filter(elapsedTime < 40000) %>%
  filter(!is.na(as.numeric(value))) %>%
  filter(!is.na(elapsedTime)) %>%
  mutate(element = factor(element)) %>%
  mutate(value_raw=value) %>%
  mutate_at(vars(value), log) %>% #
  rename(value_log=value)


## Quick plot the trends
geochem_plot <- ggplot(geochem_long, aes(x = value_raw, y = upper_age)) +
  geom_lineh() +
  #geom_smooth()+
  scale_y_reverse() +
  geom_point() +
  facet_geochem_gridh(vars(element)) +
  labs(x = NULL) +
  labs(y = NULL)
#ggtitle("XRF")
geochem_plot

# set dataset to analyze
#df <- geochem_long

#model S HGAM : similar smootheness between groups (spp) without global smooth 
set.seed(10) #set a seed so this is repeatable
grainsize_gam_S <- gam(value_sqrt ~ s(negAge, element, k=20, bs="fs"),
                    weights = elapsedTime/mean(elapsedTime),
                    data=grainsize_long,
                    method = "REML")

summary(grainsize_gam_S)
gam.check(grainsize_gam_S)
draw(grainsize_gam_S)

#model I HGAM: different smootheness for each taxa without global smooth
grainsize_gam_I<- gam(value_sqrt ~ s(negAge, by=element, k=20, bs="fs") +
                     s(element, bs="re"),
                   weights = elapsedTime/mean(elapsedTime),
                   data=grainsize_long, 
                   method = "REML")

gam.check(grainsize_gam_I)
draw(grainsize_gam_I)

#Compare different model fits using AIC
AIC_table <- AIC(grainsize_gam_S, grainsize_gam_I)%>%
  rownames_to_column(var= "Model")%>%
  mutate(data_source = rep(c("diatom_data")))%>%
  group_by(data_source)%>%
  mutate(deltaAIC = AIC - min(AIC))%>%
  ungroup()%>%
  dplyr::select(-data_source)%>%
  mutate_at(.vars = vars(df,AIC, deltaAIC), 
            .funs = funs(round,.args = list(digits=0)))

AIC_table

## Here the synthetic data to predict should be over the range of diatom ages to get the same ages for the synchronous/asynchronous model

#Create synthetic data to predict over a range of ages: here match with diatom samples
grainsize_plot_data <- with(grainsize_long, as_tibble(expand.grid(negAge = seq(min(diat_data$negAge), max(diat_data$negAge)), element = factor(levels(grainsize_long$element)))))

grainsize_modS_fit <- predict(grainsize_gam_S, 
                         newdata = grainsize_plot_data,
                         se.fit = TRUE)

grainsize_modI_fit <- predict(grainsize_gam_I,
                         newdata = grainsize_plot_data,
                         se.fit = TRUE)

#non-shared trends
grainsize_plot_data$modS_fit <- as.numeric(grainsize_modS_fit$fit)
grainsize_plot_data$modI_fit <- as.numeric(grainsize_modI_fit$fit)

# comparing non-shared trends
grainsize_plot_data <- gather(grainsize_plot_data, key=model, value=fit, modS_fit, modI_fit)

grainsize_plot_data <- mutate(grainsize_plot_data, se= c(as.numeric(grainsize_modS_fit$se.fit),
                                               as.numeric(grainsize_modI_fit$se.fit)),
                         upper = exp(fit + (2 * se)),
                         lower = exp(fit - (2 * se)),
                         fit   = exp(fit))


#Plot the model output for non-shared trends, with means plus standard deviations for each model.
grainsize_plot_model_labels <- paste("Model", c("S", "I"))
grainsize_plot_model_labels <- factor(grainsize_plot_model_labels, levels = grainsize_plot_model_labels)

#non-shared trends
theme_set(theme_bw())
theme_update(panel.grid = element_blank())

grainsize_plot <- ggplot(grainsize_plot_data) +
  facet_wrap(~element, nrow = 4,scales = "free_y")+
  geom_ribbon(aes(x=negAge,
                  ymin = lower,
                  ymax = upper,
                  fill = model),
              alpha=0.2)+
  geom_point(data= grainsize_long, aes(x = negAge, y = value_raw), size=0.06) +
  geom_line(aes(x = negAge, y = fit, color = model))+
  labs(y = "Absolute counts", x = "Age (cal yr BP)") +
  scale_fill_brewer(name = "", palette = "Dark2",
                    labels = grainsize_plot_model_labels) +
  scale_colour_brewer(name = "",
                      palette = "Dark2", labels = grainsize_plot_model_labels)+
  theme(legend.position = "top",
        strip.text = element_text(size=10))

grainsize_plot

# ggsave("outputs/pollen_plot.png",
#        plot = pollen_plot ,
#        width = 10,
#        height=8,
#        units="in",
#        dpi = 300)


## save model results for later use
#write.csv(pollen_plot_data, "outputs/pollen-HGAMs-fitted-values.csv", row.names = FALSE)
```

```{r}
calc_1st_deriv = function(fit_before, fit_after,delta) {
  (fit_after-fit_before)/(2*delta)
}

set.seed(10) #set a seed so this is repeatable
n_sims = 250
n_length = 240

years <- seq(min(grainsize_plot_data$negAge),
             max(grainsize_plot_data$negAge),
             length.out = n_length)

diff(years)
model <- grainsize_gam_I
pred <- grainsize_modS_fit

# Generate multivariate normal simulations of model coefficients
random_coefs <- t(rmvn(n_sims, mu = coef(model),V = vcov(model)))

confint_sims <- crossing(element=unique(grainsize_plot_data$element),
                         negAge = seq(min(grainsize_plot_data$negAge),
                                      max(grainsize_plot_data$negAge),
                                      length.out = n_length))

map_pred_sims <- predict(model,
                         confint_sims,
                         type = "lpmatrix") %*% random_coefs %>%
  as_data_frame() %>%
  bind_cols(confint_sims)%>%
  gather(key = simulation, value = pred, -negAge)


#specifying the step size for numerical derivative calculations
delta = 0.01

#calculating the predicted value for the current year plus delta
step_ahead_fits = confint_sims %>%
  mutate(negAge = negAge+delta)%>%
  predict(model, 
          ., type = "lpmatrix") %*% random_coefs 


#calculating the predicted value for the current year minus delta
step_behind_fits = confint_sims %>%
  mutate(negAge = negAge-delta)%>%
  predict(model,
          ., type = "lpmatrix") %*% random_coefs 


#using the predicted values for year plus and minus delta to calculate
#derivatives for each species for each simulation
derivs <- calc_1st_deriv(step_behind_fits,step_ahead_fits,delta = delta)%>%
  as_data_frame()%>%
  bind_cols(confint_sims)%>%
  gather(key = simulation,value = deriv, -element,-negAge)

#Creating summaries of derivatives for each simulation for each year
deriv_summaries <- derivs %>%
  group_by(negAge,simulation)%>%
  summarize(deriv_mean = mean(deriv),
            deriv_sd = sd(deriv))%>%
  group_by(negAge)%>% #turning derivative summaries into 95% confidence intervals
  select(-simulation)%>%
  summarize_all(.funs = list(lower = ~quantile(.,probs = 0.025),
                             upper = ~quantile(.,probs = 0.975),
                             med   = ~quantile(.,probs = 0.5)))

#Plotting mean rate of change plus the 95% CI
mean_plot <- deriv_summaries %>%
  ggplot(aes(x = negAge, 
             y = deriv_mean_med, 
             ymin = deriv_mean_lower,
             ymax = deriv_mean_upper))+
  geom_ribbon(fill="grey")+
  geom_line()+
  geom_point() +
  geom_hline(yintercept = 0, linetype=2) +
  scale_y_continuous("Average rate of change of log-abundance")+
  xlab("Cal years BP") +
  ggtitle("Diatoms") +
  #ylab("Average rate of change of log-abundance") +
  theme_bw()
mean_plot 

#Plotting standard deviation of rate of change plus the 95% CI
sd_plot <- deriv_summaries %>%
  ggplot(aes(x = negAge, 
             y = deriv_sd_med, 
             ymin=deriv_sd_lower,
             ymax=deriv_sd_upper))+
  geom_ribbon(fill="grey")+
  geom_line()+
  geom_hline(yintercept = 0, linetype=2) +
  scale_y_continuous("")+
  xlab("Cal years BP") +
  theme_bw()
sd_plot

## save derivative summaries for later use
write.csv(deriv_summaries, "outputs/grainsize-derivatives.csv", row.names = FALSE)

## Save plot
ggsave("outputs/diatoms_derivatives.png",
       plot = last_plot(),
       width=8,
       height=6,
       units="in",
       dpi = 300)
```


## Univariate GAMs for geochemistry record
```{r}

d13C <- geochem_long %>% filter(element=="d13C")
C_N <- geochem_long %>% filter(element=="TC_TN")

#model GAM:
set.seed(10) #set a seed so this is repeatable

d13C_gam <- gam(abs(value_raw) ~ s(negAge, k=100, bs="ad"),  
                    weights = elapsedTime / mean(elapsedTime),
                    data=d13C,  select = TRUE, 
                    method = "REML")

plot(d13C_gam, scale = 0)
gam.check(d13C_gam)
summary(d13C_gam)

## Here the synthetic data to predict should be over the range of diatom ages to get the same ages for the synchronous/asynchronous model
## see negAge argument
d13C_plot_data <- with(d13C, 
                     as_tibble(expand.grid(negAge = seq(min(diat_data$negAge), max(diat_data$negAge)))))
                                                            

# Predict over the range of new values
d13C_mod_fit <- predict(d13C_gam, 
                      newdata = d13C_plot_data,
                      se.fit = TRUE,
                      type = "response")

#
d13C_plot_data$mod_fit <- as.numeric(d13C_mod_fit$fit)


# For one model only
d13C_plot_data <- gather(d13C_plot_data, key=model, value=fit, mod_fit)
d13C_plot_data <- mutate(d13C_plot_data, se= c(as.numeric(d13C_mod_fit$se.fit)),
                           upper = exp(fit + (2 * se)),
                           lower = exp(fit - (2 * se)),
                           fit   = exp(fit))

# Plot
theme_set(theme_bw())
theme_update(panel.grid = element_blank())

d13C_plt <- ggplot(d13C_plot_data) +
  geom_ribbon(aes(x=negAge,
                  ymin = lower,
                  ymax = upper,
                  fill = model),
              alpha=0.2)+
  geom_point(data= d13C, aes(x = negAge, y = value_raw), size=0.06) +
  geom_line(aes(x = negAge, y = fit, color = model))+
  #scale_y_continuous(limits = c(0,100)) +
  labs(y = "Ti (counts)", x = "Age (cal yr BP)") +
  scale_fill_brewer(name = "", palette = "Dark2") +
  scale_colour_brewer(name = "",
                      palette = "Dark2")+
  theme(legend.position = "top",
        strip.text = element_text(size=10))

d13C_plt

##Derivatives and posterior distribution simulation
#Function for calculating first derivatives of time series given a before,
#after, and delta step size
calc_1st_deriv = function(fit_before, fit_after,delta) {
  (fit_after-fit_before)/(2*delta)
}

set.seed(10) #set a seed so this is repeatable
n_sims = 250
n_length = 240

years <- seq(min(d13C_plot_data$negAge),
             max(d13C_plot_data$negAge),
             length.out = n_length)

model <- d13C_gam
pred <- d13C_mod_fit

# Generate multivariate normal simulations of model coefficients
random_coefs <- t(rmvn(n_sims, mu = coef(model),V = vcov(model)))

confint_sims <- crossing(negAge = seq(min(d13C_plot_data$negAge),
                                      max(d13C_plot_data$negAge),
                                      length.out = n_length))

map_pred_sims <- predict(model,
                         confint_sims,
                         type = "lpmatrix") %*% random_coefs %>%
  as_data_frame() %>%
  bind_cols(confint_sims)%>%
  gather(key = simulation, value = pred, -negAge)


#specifying the step size for numerical derivative calculations
delta = 0.01

#calculating the predicted value for the current year plus delta
step_ahead_fits = confint_sims %>%
  mutate(negAge = negAge+delta)%>%
  predict(model, 
          ., type = "lpmatrix") %*% random_coefs 


#calculating the predicted value for the current year minus delta
step_behind_fits = confint_sims %>%
  mutate(negAge = negAge-delta)%>%
  predict(model,
          ., type = "lpmatrix") %*% random_coefs 


#using the predicted values for year plus and minus delta to calculate
#derivatives for each species for each simulation
derivs <- calc_1st_deriv(step_behind_fits,step_ahead_fits,delta = delta)%>%
  as_data_frame()%>%
  bind_cols(confint_sims)%>%
  gather(key = simulation,value = deriv, -negAge)

#Creating summaries of derivatives for each simulation for each year
deriv_summaries <- derivs %>%
  group_by(negAge)%>%
  summarize(deriv_mean = mean(deriv),
            deriv_sd = sd(deriv))%>%
  group_by(negAge)%>% #turning derivative summaries into 95% confidence intervals
  #select(-simulation)%>%
  summarize_all(.funs = list(lower = ~quantile(.,probs = 0.025),
                             upper = ~quantile(.,probs = 0.975),
                             med   = ~quantile(.,probs = 0.5)))

#Plotting mean rate of change plus the 95% CI
mean_plot <- deriv_summaries %>%
  ggplot(aes(x = negAge, 
             y = deriv_mean_med, 
             ymin = deriv_mean_lower,
             ymax = deriv_mean_upper))+
  geom_ribbon(fill="grey")+
  geom_line()+
  geom_hline(yintercept = 0, linetype=2) +
  scale_y_continuous("")+
  xlab("Cal years BP") +
  theme_bw()
mean_plot 

#Plotting standard deviation of rate of change plus the 95% CI
sd_plot <- deriv_summaries %>%
  ggplot(aes(x = negAge, 
             y = deriv_sd_med, 
             ymin=deriv_sd_lower,
             ymax=deriv_sd_upper))+
  geom_ribbon(fill="grey")+
  geom_line()+
  geom_hline(yintercept = 0, linetype=2) +
  scale_y_continuous("")+
  xlab("Cal years BP") +
  theme_bw()
sd_plot

# Save derivative results
write.csv(deriv_summaries, "outputs/d13C_derivatives.csv", row.names = FALSE)

```


Generalized Least Squares (GLS) -- **Synchronous model**
+  Modeling effects of pollen rates of change on diatom rate of change
```{r}
# Read in functions
source("scripts/functions_custom.R")

# Read in smoothed derivative proxy (diatoms, native pollen, and agropastoralism) time series
pollen_deriv <- read.csv("outputs/pollen-derivatives.csv") %>%
  select(negAge, deriv_mean_med, deriv_mean_lower, deriv_mean_upper)
  select(negAge,deriv_mean_med) %>%
  rename(pollen_deriv=deriv_mean_med) %>%
  rename(age=negAge) %>% 
  data.frame()
pollen_deriv$age <- round(pollen_deriv$age, 1)
round(diff(pollen_deriv$age, 1))[1]

diatom_deriv <- read.csv("outputs/diatom-derivatives.csv")  %>%
  select(negAge, deriv_mean_med, deriv_mean_lower, deriv_mean_upper)
  select(negAge,deriv_mean_med) %>%
  rename(diatom_deriv=deriv_mean_med) %>%
  rename(age=negAge) %>% 
  data.frame()
diatom_deriv$age <- round(diatom_deriv$age, 1)

grainsize_deriv <- read.csv("outputs/grainsize-derivatives.csv")  %>%
  select(deriv_mean_med, deriv_mean_lower, deriv_mean_upper)
  select(negAge,deriv_mean_med) %>%
  rename(grainsize_deriv=deriv_mean_med) %>%
  rename(age=negAge) %>% 
  data.frame()
grainsize_deriv$age <- round(grainsize_deriv$age, 1)

## Synchrony analysis
# pollen ~ diatoms
df <- cbind(diatom_deriv, pollen_deriv, grainsize_deriv)
df[,c(3,5)] <- NULL
#colnames(df) <- c("diat_deriv_mean", "diat_sd_mean", "agropast_deriv_mean", "agropast_sd_mean")

#fitting GLS model without autocorrelated residuals
diat.pollen.gls <- gls(diatom_deriv ~ grainsize_deriv, data=df)
summary(diat.agropast.gls)

#check autocorrelation of the residuals
acf(residuals(diat.pollen.gls)) # evidence for correlated residuals
pacf(residuals(diat.pollen.gls)) # indicates AR1

#fitting GLS model with autocorrelated residuals
diat.pollen.gls <- gls(diatom_deriv ~ grainsize_deriv, 
                         data=df, correlation=corARMA(p=1))

#pseudo R2 (gls doesn't provide R2)
diat.pollen.gls.R2 <- cor(df$diatom_deriv, 
                          predict(diat.pollen.gls))^2 

df$diat.pollen.predicted <- predict(diat.pollen.gls)

#plotting diatom vs agropastoralismr
diatoms_pollen_plt <- ggplot(data=df, aes(x=grainsize_deriv, y=diatom_deriv)) + 
  geom_point(shape=21, fill="gray50", color="black", size=4, alpha=0.5) +
  geom_line(aes(x=grainsize_deriv, y=diat.pollen.predicted), size=2, color="red4", alpha=0.6) +
  ylab("Diatoms (st. dev of rate of change of log-abundance)") + 
  xlab("pollen-indicators (st. dev of rate of change of log-abundance)") +
  ggtitle("Diatoms vs. Pollen") +
  theme(text=element_text(size=9), plot.title=element_text(size = 12))

diatoms_pollen_plt

```

Generalized Least Squares (GLS) -- **Asynchronous model**

The **asynchronous model** consists in two steps:

+  Generating lagged time series: diatom samples (response) are paired with antecedent samples of predictors (pollen)
+  Modeling time-delayed effects of pollen rates of change (separately) on diatom rate of change

```{r}
### Backward lags
# lags * temp resolution = 40 * 1000 = 40000

lags<-1:20

# rename datasets for the function to work
diat <- diatom_deriv
pollen <- pollen_deriv 

#backward dataset 
lag.data.backward <- backwardLags(
  lags=lags, 
  reference.data=diatom_deriv, 
  data.to.lag=pollen_deriv
)

# Fitting a GLS model per lag on backward datasets
backward.results <- modelLagData(
  model.formula="diatom_deriv ~ pollen_deriv", 
  lagged.data=lag.data.backward
)

backward.results$value <- round(backward.results$value, 2)

# Fitting a null model
backward.results.random <- modelRandomLagData(
  lagged.data=lag.data.backward, 
  model.formula="diatom_deriv ~ pollen_deriv", 
  iterations=1000
)

backward.results.random$value <- round(backward.results.random$value, 2)

# Plot model results
## Set axes limits
max.lag = max(c(backward.results$lag))
max.coefficient = round(max(c(backward.results[backward.results$variable=="Coefficient", "value"], backward.results.random[backward.results.random$variable=="Coefficient", "upper"])) + 0.1, 1)
min.coefficient = round(min(c(backward.results[backward.results$variable=="Coefficient", "value"], backward.results.random[backward.results.random$variable=="Coefficient", "lower"])) - 0.1, 1)
max.R2 = round(max(c(backward.results[backward.results$variable=="R2", "value"])), 1)

library(viridis)
viridis.colors <- viridis(10, option="D")

backward.plot.coefficient <- ggplot(data=subset(backward.results, variable=="Coefficient"), aes(x=lag, y=value)) +
  geom_ribbon(data=subset(backward.results.random, variable=="Coefficient"), aes(ymin=lower, ymax=upper), alpha=0.3, fill="light grey") +
  geom_line(data=subset(backward.results.random, variable=="Coefficient"), aes(x=lag, y=value), alpha=0.6, color="light grey", size=1) +
  geom_hline(yintercept=0, color="black", linetype=2) +
  geom_ribbon(aes(ymin=lower,ymax=upper), alpha=0.3, fill=viridis.colors[2]) +
  geom_line(size=1.5, color=viridis.colors[1]) +
  ggtitle(expression("Pollen" %->% "Diatoms")) +
  theme(legend.position="none") +
  xlab("") +
  ylab("Standardized coefficient") +
  scale_y_continuous(breaks=seq(min.coefficient, max.coefficient, by=0.8)) +
  #scale_x_reverse()+
  theme(axis.text.y = element_text(size=16),
        axis.text.x = element_text(size=16),
        axis.title.y = element_text(size=16),
        plot.title = element_text(size=16),
        plot.margin = unit(c(0, 0, 0, 0), "cm"),
        axis.title.x=element_blank()) +
        #axis.text.x=element_blank(),
        #axis.line.x=element_blank(),
        #axis.ticks.x = element_blank()) +
  theme_classic()
  #coord_cartesian(ylim = c(min.coefficient, max.coefficient + 0.5))

#backward.plot.coefficient

backward.plot.R2 <- ggplot(data=subset(backward.results, variable=="R2"), aes(x=lag, y=value, group=variable)) +
  geom_ribbon(data=subset(backward.results.random, variable=="R2"), aes(ymin=lower, ymax=upper), alpha=0.3, fill="light grey") +
  geom_line(data=subset(backward.results.random, variable=="R2"), aes(x=lag, y=value), alpha=0.6, color="light grey", size=1.5) +
  geom_line(size=1.5, color=viridis.colors[2]) +
  theme(legend.position="none") +
  xlab("Years (before Diatom samples)") +
  ylab("Pseudo R squared") +
  scale_y_continuous(breaks=seq(0, max.R2, by=0.1)) +
  #scale_x_reverse()+
  theme(axis.text.y = element_text(size=16),
        axis.text.x = element_text(size=16),
        plot.title = element_text(size=16),
        axis.title.y = element_text(size=16),
        plot.margin = unit(c(0.2, 0.5, 0, 0), "cm")) +
  theme_classic() +
  coord_cartesian(ylim = c(0, max.R2 + 0.05))

#backward.plot.R2

#Combine the two plots
library(cowplot)
plot_composite <- plot_grid(backward.plot.coefficient, 
                            backward.plot.R2, ncol = 1, 
                            rel_heights = c(1, 1), align="v") + 
                            theme(plot.margin = unit(c(0.5, -1, 0.5, 0.5), "cm"))
plot_composite

# save plot
ggsave("outputs/pollen_diatoms_asycnchronousModel.png",
       plot = plot_composite,
       width=8,
       height=6,
       units="in",
       dpi = 300)

```


